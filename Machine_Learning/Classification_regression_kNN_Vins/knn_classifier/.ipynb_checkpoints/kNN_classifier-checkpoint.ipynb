{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification binaire de vins blancs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à prédire la note de vins rouges.\n",
    "On utilisera l'algorithme kNN (classifieur) avec une recherche sur grille ainsi qu'une fonction de validation croisée implémentées manuellement puis comparées avec celles utilisées par scikit-learn.\n",
    "La comparaison se fait sur la précision des modèles entraînés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('winequality-white.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualisation des données\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Extraction des données\n",
    "X = data.as_matrix(data.columns[:-1])\n",
    "y = data.as_matrix([data.columns[-1]])\n",
    "y = y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse des notes possibles pour les vins\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de validation croisée \"maison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données en jeux d'entraînement et de test\n",
    "from sklearn import model_selection\n",
    "X_train_total, X_test, y_train_total, y_test = \\\n",
    "model_selection.train_test_split(X, y,\n",
    "                                test_size=0.25 # 25% des données dans le jeu de test\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des données X\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train_total)\n",
    "X_train_total = std_scale.transform(X_train_total)\n",
    "X_test = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Nombre de voisins : 3\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 53.06 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 55.78 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 54.83 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 51.56 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 54.16 %\n",
      "Accurracy moyenne du modèle '3 voisins' : 53.88 %\n",
      "============================================================\n",
      "Nombre de voisins : 5\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 52.79 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 54.01 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 55.10 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 53.06 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 53.89 %\n",
      "Accurracy moyenne du modèle '5 voisins' : 53.77 %\n",
      "============================================================\n",
      "Nombre de voisins : 7\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 53.88 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 52.65 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 54.29 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 53.06 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 51.84 %\n",
      "Accurracy moyenne du modèle '7 voisins' : 53.14 %\n",
      "============================================================\n",
      "Nombre de voisins : 9\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 54.01 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 52.38 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 54.15 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 52.65 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 53.62 %\n",
      "Accurracy moyenne du modèle '9 voisins' : 53.36 %\n",
      "============================================================\n",
      "Nombre de voisins : 11\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 56.46 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 51.56 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 54.97 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 52.93 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 53.21 %\n",
      "Accurracy moyenne du modèle '11 voisins' : 53.82 %\n",
      "============================================================\n",
      "Nombre de voisins : 13\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 55.78 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 52.38 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 56.46 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 51.43 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 54.43 %\n",
      "Accurracy moyenne du modèle '13 voisins' : 54.10 %\n",
      "============================================================\n",
      "Nombre de voisins : 15\n",
      "Numéro de fold de test : 1\n",
      "Accurracy du fold : 53.88 %\n",
      "Numéro de fold de test : 2\n",
      "Accurracy du fold : 51.70 %\n",
      "Numéro de fold de test : 3\n",
      "Accurracy du fold : 54.97 %\n",
      "Numéro de fold de test : 4\n",
      "Accurracy du fold : 52.38 %\n",
      "Numéro de fold de test : 5\n",
      "Accurracy du fold : 54.30 %\n",
      "Accurracy moyenne du modèle '15 voisins' : 53.44 %\n",
      "============================================================\n",
      "Liste accuracy : [53.8798155005522, 53.77082347263599, 53.143859453740575, 53.36251171682862, 53.82487401509034, 54.097651065883376, 53.44451559614296]\n",
      "Meilleur hyperparamètre : 13\n",
      "Accuracy : 54.10 %\n"
     ]
    }
   ],
   "source": [
    "from kNN_classifier_fonction import Validation_croisee\n",
    "\n",
    "# Paramètres à choisir, ici le nombre de voisins :\n",
    "n_neighbors = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "# Nombre de folds à choisir : \n",
    "cv = 5\n",
    "\n",
    "# Retour de la position du meilleur K dans la liste n_neighbors grâce à la fonction :\n",
    "K_opt = Validation_croisee(X_train_total, y_train_total, n_neighbors, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur hyperparamètre : 13\n",
      "\n",
      "Sur le jeu de test : 54.61 %\n"
     ]
    }
   ],
   "source": [
    "# Test du modèle le plus performant\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = K_opt)\n",
    "model.fit(X_train_total, y_train_total)  #fit the model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "result = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Meilleur hyperparamètre : {}\".format(K_opt))\n",
    "print(\"\\nSur le jeu de test : {:0.2f} %\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction GridsearchCV implémentée dans Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'n_neighbors': 13}\n",
      "Résultats de la validation croisée :\n",
      "\taccuracy = 0.539 (+/-0.030) for {'n_neighbors': 3}\n",
      "\taccuracy = 0.538 (+/-0.017) for {'n_neighbors': 5}\n",
      "\taccuracy = 0.531 (+/-0.017) for {'n_neighbors': 7}\n",
      "\taccuracy = 0.534 (+/-0.015) for {'n_neighbors': 9}\n",
      "\taccuracy = 0.538 (+/-0.034) for {'n_neighbors': 11}\n",
      "\taccuracy = 0.541 (+/-0.039) for {'n_neighbors': 13}\n",
      "\taccuracy = 0.534 (+/-0.025) for {'n_neighbors': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import neighbors, metrics\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Choisir un score à optimiser, ici l'accuracy (proportion de prédictions correctes)\n",
    "score = 'accuracy'\n",
    "\n",
    "# Non randomisation des folds (shuffle est normalement \"False\" par défaut)\n",
    "cv_GridSearch=model_selection.KFold(n_splits=5,shuffle=False)\n",
    "\n",
    "# Créer un classifieur kNN avec recherche d'hyperparamètre par validation croisée\n",
    "clf = model_selection.GridSearchCV(neighbors.KNeighborsClassifier(), # un classifieur kNN\n",
    "param_grid, # hyperparamètres à tester\n",
    "cv=cv_GridSearch, # nombre de folds de validation croisée\n",
    "scoring=score # score à optimiser\n",
    ")\n",
    "\n",
    "# Optimiser ce classifieur sur le jeu d'entraînement\n",
    "clf.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\"),\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], # score moyen\n",
    "clf.cv_results_['std_test_score'], # écart-type du score\n",
    "clf.cv_results_['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print(\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, # critère utilisé\n",
    "    mean, # score moyen\n",
    "    std * 2, # barre d'erreur\n",
    "    params # hyperparamètre\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur hyperparamètre : {'n_neighbors': 13}\n",
      "Sur le jeu de test : 54.61 %\n"
     ]
    }
   ],
   "source": [
    "# Test du modèle le plus performant\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Meilleur hyperparamètre : {}\".format(clf.best_params_))\n",
    "result = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Sur le jeu de test : {:0.2f} %\".format(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
